---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Developing SALT targets

## Available data and shortcomings of IRS-published aggregates for SALT targets

We want the TMD national microdata file to include *potential* SALT deductions for the entire universe of tax units -- itemizers and non-itemizers (and nonfilers) -- before application of any caps. The TMD microdata include estimates of these concepts.

We want state-weighted TMD microdata files to reflect *potential* SALT deductions in individual states, meaning we need state targets that reflect potential SALT deductions, not SALT deductions reported on 2021 tax returns.

IRS has reported actual SALT deductions in 2021, but those are sharply reduced from earlier years due to the drop in itemization caused by the TCJA standard deduction increase. (The IRS does report amounts prior to the SALT cap, but only for those who itemized.)

(Note that the same issue arises for Congressional districts.)

### National TMD microdata

The national TMD microdata include two uncapped SALT variables:

-   [e18400](https://taxcalc.pslmodels.org/guide/input_vars.html#e18400): Itemizable state and local income/sales taxes, and

-   [e18500](https://taxcalc.pslmodels.org/guide/input_vars.html#e18500): Itemizable real-estate taxes paid

(links are to Tax-Calculator documentation). The TMD data also include capped variants of these variables.

These variables are actual or estimated amounts available to be deducted in the 2015 PUF base year, grown to 2021 at a rate intended to capture growth in state and local taxes. Thus, they are unaffected by the TCJA SALT cap or the fact that many 2015 itemizers will be non-itemizers in 2021 due to the TCJA standard deduction increase.

While they do not represent the full universe of potential SALT deductions, they do represent potential SALT deductions for those who itemized in 2015, when the standard deduction was lower and there were many more itemizers than in 2018 and later, when TCJA was in effect. Thus, e18400 and e18500 are a pretty good starting point for subnational data files.

We want to target `e18400` and `e18500` for each state (and, in a separate part of the TMD project, each Congressional district), which means we need to find or develop aggregate targets for these variables by AGI range. Unfortunately, we do not have data on these variables for the full universe. Instead, we have IRS-published data by state and Congressional district, by AGI range, for people who itemized in 2021. Because of the TCJA's higher standard deduction, the published data represent far fewer itemizers than are in our national PUF-based data and do not capture people who might become itemizers if the SALT cap were raised or if the standard deduction were lowered. Thus, these data are not directly suitable as targets.

One possible approach, which we have taken here and in the Congressional districts part of the project, is to assume that the aggregate national uncapped itemizable deductions in our TMD data (`e18400` and `e18500`) are distributed across subnational areas in the same way that the published subnational data are distributed: for example, if a state has 7% of the nation's real estate deductions for 2021 itemizers, it will have 7% of the aggregate amount of potential real estate deductions in our TMD file (`e18500`), which includes many potential itemizers who would not have itemized in 2021. We use the same approach for other tax-itemizatoion variables.

This seems like a reasonable first-cut assumption if we don't have direct data on potential real estate tax deductions of non-itemizers in 2021 -- i.e., assume they are distributed across states in the same way as real estate tax deductions of itemizers.

**Taxes-paid excerpt from 2021 Schedule A**

![](images/clipboard-565930362.png)

## Setup

```{r}
#| label: setup

source(here::here("R", "libraries.R"))
source(here::here("R", "constants.R"))
source(here::here("R", "functions.R"))

```

```{r}
#| label: get-data
#| output: false

soilong <- readRDS(fs::path(DINTERMEDIATE, "soilong.rds"))
agilabels <- read_csv(fs::path(DINTERMEDIATE, "agilabels.csv"))

fpath <-  fs::path(TMDDATA, "cached_allvars.csv")
tmd2021 <- vroom(fpath)
ns(tmd2021)

```

## Basic SALT information

### IRS-published U.S. amounts in 2021

Note that a18425 is the largest value by far.

```{r}
#| label: salt-amounts-2021


soilong |> 
  filter(str_sub(vname, 1, 3)=="a18", stabbr=="US", agistub==0, year==2021) |> 
  select(stabbr, vname, year, value, udescription) |> 
  gt() |> 
  tab_header(title="SALT-related variables in 2021, amounts for the U.S. in $ billions",
             subtitle = "SOI Historical Table 2") |> 
  fmt_currency(columns = value, scale=1e-9, decimals=1)


```

### IRS-published U.S. amounts over time

Note that a18425 is \$0 in the lowest AGI range.

```{r}
#| label: salt-amounts-over-time

soilong |> 
  filter(str_sub(vname, 1, 3)=="a18", stabbr=="US", agistub==0) |> 
  select(stabbr, vname, year, value, udescription) |> 
  pivot_wider(names_from = year) |> 
  gt() |> 
  tab_header(title="SALT-related variables over time, amounts for the U.S. in $ billions",
             subtitle = "SOI Historical Table 2") |> 
  fmt_currency(columns = -c(stabbr, vname, udescription), scale=1e-9, decimals=1) |> 
  sub_missing(columns=everything(),
              missing_text="--") 
  

```

### IRS-published U.S. amounts by AGI range over time

```{r}
#| label: income-sales-tax-by-agirange-amounts-over-time

soilong |> 
  filter(vname=="a18425", stabbr=="US") |> 
  select(year, agistub, agilabel, value) |> 
  pivot_wider(names_from = year) |> 
  gt() |> 
  tab_header(title="a18425 State and local income taxes amount, over time, amounts for the U.S. in $ billions",
             subtitle = "SOI Historical Table 2") |> 
  fmt_currency(columns = -c(agistub, agilabel), scale=1e-9, decimals=1) |> 
  sub_missing(columns=everything(),
              missing_text="--") 


```

## How tmd sums compare to IRS-published aggregates

### Potentially deductible amounts

The following table shows 2021 sums for tax filers (data_source==1) in the TMD data and the IRS-published aggregates that correspond most closely to the TMD concepts. Note that for the TMD variable `e18400` (Itemizable state and local income/sales taxes) the closest available IRS-published aggregates are `a18425` (State and local income taxes amount) and `a18450` (State and local general sales tax amount). Because taxpayers can only deduct one or the other (income or sales taxes), the sum of `a18425` and `a18450` is relevant.

It is clear, though, that the TMD 2021 estimated values (for the universe of 2015 itemizers) are far greater than the IRS-published amounts from 2021 tax returns.

```{r}
#| label: tmd-compare-amounts

tmdvars <- tmd2021 |> 
  select(RECID, data_source, s006, e18400, e18500) |> 
  summarise(across(c(e18400, e18500),
                   \(x) sum(s006 * x)),
            .by=data_source) |> 
  mutate(src="tmd") |> 
  filter(data_source==1) |> 
  select(-data_source) |> 
  pivot_longer(-src) |> 
  mutate(description=case_when(name=="e18400" ~ "Itemizable state and local income/sales taxes",
                               name=="e18500" ~ "Itemizable real-estate taxes paid",
                               .default = "ERROR"),
         basename=str_sub(name, 2, -1))

soivars <- soilong |> 
  filter(stabbr=="US", agistub==0, year==2021) |> 
  filter(vname %in% c("a18425", "a18450", "a18500")) |> 
  mutate(src="irs", basename=str_sub(vname, 2, -1)) |> 
  select(src, name=vname, value, description, basename)
  
comp <- bind_rows(tmdvars, soivars)

comp |> 
  arrange(basename, desc(src)) |> 
  select(-basename) |> 
  gt() |> 
  tab_header(title="TMD and IRS amounts for 2021 filers, key SALT-related variables",
             subtitle = "Amounts are in $ billions") |> 
  fmt_currency(columns = value,
               scale=1e-9,
               decimals=2)

```

### Numbers of potential itemizers with SALT amounts

The next table shows the number of taxpayers who have nonzero values for key SALT-related variables.

```{r}
#| label: tmd-compare-numbers

tmdvars <- tmd2021 |> 
  select(RECID, data_source, s006, e18400, e18500) |> 
  summarise(across(c(e18400, e18500),
                   \(x) sum(s006 * (x != 0))),
            .by=data_source) |> 
  mutate(src="tmd") |> 
  filter(data_source==1) |> 
  select(-data_source) |> 
  pivot_longer(-src) |> 
  mutate(description=case_when(name=="e18400" ~ "Itemizable state and local income/sales taxes",
                               name=="e18500" ~ "Itemizable real-estate taxes paid",
                               .default = "ERROR"),
         basename=str_sub(name, 2, -1))

soivars <- soilong |> 
  filter(stabbr=="US", agistub==0, year==2021) |> 
  filter(vname %in% c("n18425", "n18450", "n18500")) |> 
  mutate(src="irs", basename=str_sub(vname, 2, -1)) |> 
  select(src, name=vname, value, description, basename)
  
comp <- bind_rows(tmdvars, soivars)

comp |> 
  arrange(basename, desc(src)) |> 
  select(-basename) |> 
  gt() |> 
  tab_header(title="Numbers of 2021 filers with nonzero amounts for key SALT-related variables",
             subtitle = "Amounts are in $ billions") |> 
  fmt_number(columns = value,
             scale=1,
             decimals=0)

```

## How closely do current SALT data correspond to pre-TCJA SALT data, using IRS-published data for both?

Explain why this is of interest.

```{r}
#| label: salt-shares-data

salt <- soilong |> 
  filter(year %in% c(2017, 2018, 2021),
         vname=="a18425",
         !stabbr %in% c("US", "OA", "PR")) |> 
  mutate(agistubf=factor(agistub, levels=agilabels$agistub, labels=agilabels$agilabel)) |> 
  select(stabbr, year, agistub, agistubf, value) |> 
  pivot_wider(names_from = year, names_prefix = "y")

saltshares <- salt |> 
  mutate(across(starts_with("y2"),
                \(x) x / sum(x)),
                .by=agistub)

```

```{r}
#| label: correlation-table

saltshares |> 
  select(-stabbr) |> 
  filter(agistub != 1) |> 
  summarise(cor2017_2018=cor(y2017, y2018, use = "complete.obs"),
            cor2018_2021=cor(y2018, y2021, use = "complete.obs"),
            .by=c(agistub, agistubf)) |> 
  gt() |> 
  tab_header(title="Correlation of SALT shares (a18425) in pairs of years") |> 
  fmt_number(columns = c(cor2017_2018, cor2018_2021), decimals=3)

```

```{r}
#| label: shares-plot
#| fig-height: 10

saltshares |> 
  filter(!stabbr %in% c("CA", "NY")) |> 
  filter(agistub != 1) |> 
  ggplot(aes(x=y2017, y=y2021)) +
  geom_point(colour="blue",
             size=0.5) +
  geom_text(aes(label=stabbr),
            colour="blue",
            size=2) +
  ggtitle("State shares of total U.S. a18425 deduction\n2017 and 2021, by AGI range",
          subtitle = "CA and NY excluded to make figure easier to see.\nLowest AGI range excluded because SALT deductions were zero.") +
  theme_bw() +
  facet_wrap(~agistubf, scales = "free",
             ncol = 3)

```

## Playground

```{r}
#| label: explore-and-take-notes
#| eval: false

skim(soilong)

soilong |> 
  filter(str_sub(vname, 1, 3)=="a18") |> 
  count(vname, year, udescription, description)

soilong |> 
  filter(str_sub(vname, 1, 3)=="a18") |> 
  count(vname, udescription)

#   vname  udescription                                 n  avail in 2021?      US amount in 2021
#   <chr>  <chr>                                    <int>
# 1 a18300 Taxes paid amount                         4125 yes; big drop 2018+; $120b
# 2 a18425 State and local income taxes amount       4125 yes; big drop 2018+; $253b biggest item by far in 2021
# 3 a18450 State and local general sales tax amount  4125 yes; big drop 2018+; $7.5b
# 4 a18460 Limited state and local taxes             2376 yes; only for 2018+; $118b
# 5 a18500 Real estate taxes amount                  4125 yes; big drop 2018+; $101b
# 6 a18800 Personal property taxes amount            3542 yes; big drop 2018+; $4.3b

soilong |> 
  filter(str_sub(vname, 1, 3)=="a18", stabbr=="US", agistub==0)

soilong |> 
  filter(str_sub(vname, 1, 3)=="a18", stabbr=="US", agistub==0, year==2021)

soilong |> filter(vname=="a18460", year==2015)

count(soilong, stabbr) # 54 -- 50 + US, DC, PR, OA

soilong |> 
  filter(vname=="a18460", year %in% 2015:2017) |> 
  skim()

soilong |> 
  filter(stabbr=="US", agistub==0, vtype=="amount", str_starts(basevname, "184")) |> 
  arrange(vname, year)

# a18425 drops 2018+ 369 --> 201
# a8450 drops 2018+ 20 --> 9
# a18460 2018+ 130 ish

salt <- soilong |> 
  filter(year %in% c(2017, 2018, 2021),
         vname=="a18425",
         agistub==0,
         !stabbr %in% c("US", "OA", "PR")) |> 
  select(stabbr, year, value) |> 
  pivot_wider(names_from = year, names_prefix = "y")

salt |> select(-stabbr) |> cor()

salt |> 
  filter(!stabbr %in% c("CA", "NY")) |> 
  ggplot(aes(x=y2017, y=y2021)) +
  geom_point(colour="blue",
             size=0.5) +
  geom_text(aes(label=stabbr),
            colour="blue",
            size=3) +
  theme_bw()
```

---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Developing SALT targets

In a perfect world our national and state data files (and our separate Congressional district files) would have *potential* SALT deductions for the entire universe of potential tax units, regardless of whether they itemize or not, before application of the TCJA SALT cap. We come reasonably close to this ideal for the *national* TMD data. The national TMD data, based on the 2015 PUF, include: (1) [e18400, Itemizable state and local income/sales taxes](https://taxcalc.pslmodels.org/guide/input_vars.html#e18400)), and (2) [e18500, Itemizable real-estate taxes paid](https://taxcalc.pslmodels.org/guide/input_vars.html#e18500) (links are to Tax-Calculator documentation). These TMD variables are based primarily on people who itemized deductions in 2015, grown to 2021 levels, before the application of the TCJA SALT cap that was in effect in 2021. Thus, while they do not represent the universe of potential SALT deductions, they do represent potential deductions for those who itemized in 2015, when the standard deduction was lower and SALT deductions are uncapped. Thus, they are a pretty good starting point for subnational data files.

We want to target e18400 and e18500 for each state (and, in a separate part of the TMD project, each Congressional district). Unfortunately, we do not have data on the amount of these variables by state and Congressional district, by AGI range. Instead, we have published data by state and Congressional district for 2021, which reflect the TCJA's higher standard deduction and SALT cap. Thus, the published data include far fewer itemizers that might exist under some policy scenarios, and far lower potential deductions than would be available if the SALT cap were raised. We cannot use the published data directly as state and Congressional district targets.

However, is there a way we can use the published data to help us construct estimates of subnational SALT targets, which by definition are unpublished?

One possible approach, which we have taken here and in the Congressional districts part of the project, is to assume that the aggregate national uncapped itemizable deductions are spread across subnational areas in the same way that the published subnational data are distributed: for example, if a state has 7% of the nation's capped real estate deductions for itemizers.

**Taxes-paid excerpt from 2021 Schedule A**

![](images/clipboard-565930362.png)

## Setup

```{r}
#| label: setup

source(here::here("R", "libraries.R"))
source(here::here("R", "constants.R"))
source(here::here("R", "functions.R"))

```

```{r}
#| label: get-data
#| output: false

soilong <- readRDS(fs::path(DINTERMEDIATE, "soilong.rds"))
agilabels <- read_csv(fs::path(DINTERMEDIATE, "agilabels.csv"))


```

## Basic SALT information

### U.S. amounts in 2021

Note that a18425 is the largest value by far

```{r}
#| label: salt-amounts-2021


soilong |> 
  filter(str_sub(vname, 1, 3)=="a18", stabbr=="US", agistub==0, year==2021) |> 
  select(stabbr, vname, year, value, udescription) |> 
  gt() |> 
  tab_header(title="SALT-related variables in 2021, amounts for the U.S. in $ billions",
             subtitle = "SOI Historical Table 2") |> 
  fmt_currency(columns = value, scale=1e-9, decimals=1)


```

### U.S. amounts over time

Note that a18425 is \$0 in the lowest AGI range.

```{r}
#| label: salt-amounts-over-time

soilong |> 
  filter(str_sub(vname, 1, 3)=="a18", stabbr=="US", agistub==0) |> 
  select(stabbr, vname, year, value, udescription) |> 
  pivot_wider(names_from = year) |> 
  gt() |> 
  tab_header(title="SALT-related variables over time, amounts for the U.S. in $ billions",
             subtitle = "SOI Historical Table 2") |> 
  fmt_currency(columns = -c(stabbr, vname, udescription), scale=1e-9, decimals=1) |> 
  sub_missing(columns=everything(),
              missing_text="--") 
  

```

### U.S. amounts by AGI range over time

```{r}
#| label: income-sales-tax-by-agirange-amounts-over-time

soilong |> 
  filter(vname=="a18425", stabbr=="US") |> 
  select(year, agistub, agilabel, value) |> 
  pivot_wider(names_from = year) |> 
  gt() |> 
  tab_header(title="a18425 State and local income taxes amount, over time, amounts for the U.S. in $ billions",
             subtitle = "SOI Historical Table 2") |> 
  fmt_currency(columns = -c(agistub, agilabel), scale=1e-9, decimals=1) |> 
  sub_missing(columns=everything(),
              missing_text="--") 


```

## How closely do current SALT data correspond to pre-TCJA SALT data

Explain why this is of interest.

```{r}
#| label: correlation

# add agi info to agistub

salt <- soilong |> 
  filter(year %in% c(2017, 2018, 2021),
         vname=="a18425",
         !stabbr %in% c("US", "OA", "PR")) |> 
  mutate(agistubf=factor(agistub, levels=agilabels$agistub, labels=agilabels$agilabel)) |> 
  select(stabbr, year, agistub, agistubf, value) |> 
  pivot_wider(names_from = year, names_prefix = "y")



saltshares <- salt |> 
  mutate(across(starts_with("y2"),
                \(x) x / sum(x)),
                .by=agistub)

saltshares |> 
  select(-stabbr) |> 
  filter(agistub != 1) |> 
  summarise(cor=cor(y2017, y2018, use = "complete.obs"),
            .by=c(agistub, agistubf)) |> 
  gt() |> 
  fmt_number(columns = cor, decimals=3)


salt |> 
  filter(!stabbr %in% c("CA", "NY")) |> 
  ggplot(aes(x=y2017, y=y2021)) +
  geom_point(colour="blue",
             size=0.5) +
  geom_text(aes(label=stabbr),
            colour="blue",
            size=3) +
  theme_bw() +
  facet_wrap(~agistub, scales = "free")


```

## Playground

```{r}
#| label: explore-and-take-notes
#| eval: false

skim(soilong)

soilong |> 
  filter(str_sub(vname, 1, 3)=="a18") |> 
  count(vname, year, udescription, description)

soilong |> 
  filter(str_sub(vname, 1, 3)=="a18") |> 
  count(vname, udescription)

#   vname  udescription                                 n  avail in 2021?      US amount in 2021
#   <chr>  <chr>                                    <int>
# 1 a18300 Taxes paid amount                         4125 yes; big drop 2018+; $120b
# 2 a18425 State and local income taxes amount       4125 yes; big drop 2018+; $253b biggest item by far in 2021
# 3 a18450 State and local general sales tax amount  4125 yes; big drop 2018+; $7.5b
# 4 a18460 Limited state and local taxes             2376 yes; only for 2018+; $118b
# 5 a18500 Real estate taxes amount                  4125 yes; big drop 2018+; $101b
# 6 a18800 Personal property taxes amount            3542 yes; big drop 2018+; $4.3b

soilong |> 
  filter(str_sub(vname, 1, 3)=="a18", stabbr=="US", agistub==0)

soilong |> 
  filter(str_sub(vname, 1, 3)=="a18", stabbr=="US", agistub==0, year==2021)

soilong |> filter(vname=="a18460", year==2015)

count(soilong, stabbr) # 54 -- 50 + US, DC, PR, OA

soilong |> 
  filter(vname=="a18460", year %in% 2015:2017) |> 
  skim()

soilong |> 
  filter(stabbr=="US", agistub==0, vtype=="amount", str_starts(basevname, "184")) |> 
  arrange(vname, year)

# a18425 drops 2018+ 369 --> 201
# a8450 drops 2018+ 20 --> 9
# a18460 2018+ 130 ish

salt <- soilong |> 
  filter(year %in% c(2017, 2018, 2021),
         vname=="a18425",
         agistub==0,
         !stabbr %in% c("US", "OA", "PR")) |> 
  select(stabbr, year, value) |> 
  pivot_wider(names_from = year, names_prefix = "y")

salt |> select(-stabbr) |> cor()

salt |> 
  filter(!stabbr %in% c("CA", "NY")) |> 
  ggplot(aes(x=y2017, y=y2021)) +
  geom_point(colour="blue",
             size=0.5) +
  geom_text(aes(label=stabbr),
            colour="blue",
            size=3) +
  theme_bw()
```
